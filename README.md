This minor project demonstrates the implementation of an end-to-end machine learning pipeline that integrates multiple concepts learned during coursework, including data preprocessing, feature scaling, model training, evaluation, and comparison. The project works with both classification and regression problems using three standard datasets: Wine, Diabetes, and California Housing. Multiple machine learning models such as Logistic Regression, Linear Regression, Decision Trees, and Random Forests are applied through a unified pipeline built using Python and Scikit-learn. The workflow includes dataset loading, train–test splitting, feature scaling with StandardScaler, model training using pipelines, and performance evaluation using appropriate metrics such as accuracy for classification and R² score for regression. The results show that ensemble-based models, particularly Random Forest, consistently outperform individual models by capturing complex patterns and reducing overfitting. This project highlights the importance of systematic model comparison, reusable pipelines, and fair evaluation while providing practical experience in applying end-to-end machine learning techniques to real-world datasets.
