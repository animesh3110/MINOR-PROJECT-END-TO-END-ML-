{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MINOR PROJECT-\n",
        "In the classes before the minor project , we learnt many topics like logistics regression , linear regression,pipelines,decision trees,random forest,etc.\n",
        "\n",
        "So the main aim of this minor project is to integrate all of these different tools into one specific project.\n",
        "\n",
        "In the class as a refrence we were taught **END TO END MACHINE LEARNING** for this minor project\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1Kauu6msJo_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXPLANATION OF ML MODEL-\n",
        "We can understand the concept of ML model by taking an example of identifying whether its day or night\n",
        "\n",
        "Dataset- images of day and night\n",
        "\n",
        "Preprocessing- noticing patterns such as bright,dark,sun,moon etc\n",
        "\n",
        "Model- distinguishing\n",
        "\n",
        "Training- identifying\n",
        "\n",
        "Testing- given 100 images the model should understand whether its day or night\n",
        "\n",
        "Hyperparameters- cloudy,foggy,snowy etc\n",
        "\n",
        "Parameters- what the model learns from the data"
      ],
      "metadata": {
        "id": "rTeHllq5LhHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASETS IN MY MODEL-\n",
        "Wine Datset\n",
        "\n",
        "Diabeties Datset\n",
        "\n",
        "California housing data set\n"
      ],
      "metadata": {
        "id": "6Py0bGkxbx1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# STEP 1: IMPORT THE REQUIRED LIBRARIES\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Classification & Regression Models\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "# Load built-in sklearn datasets\n",
        "from sklearn.datasets import load_wine, load_diabetes, fetch_california_housing\n",
        "\n",
        "# For handling data (if needed)\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "8jfUxG_JUmvG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 2: CREATE A LIST OF DATASETS\n",
        "\n",
        "from sklearn.datasets import load_wine, load_diabetes, fetch_california_housing\n",
        "\n",
        "datasets = {\n",
        "    \"Wine Dataset\"          : load_wine(),                   # Classification (3 classes of wine)\n",
        "    \"Diabetes Dataset\"      : load_diabetes(),               # Regression (disease progression)\n",
        "    \"California Housing\"    : fetch_california_housing()     # Regression (house prices)\n",
        "}\n",
        "\n",
        "# All sklearn datasets follow the same structure:\n",
        "#   dataset.data   -> features (X)\n",
        "#   dataset.target -> labels / output (y)\n",
        "#\n",
        "# This allows us to loop through each dataset and apply\n",
        "# our machine learning pipeline easily.\n",
        "\n"
      ],
      "metadata": {
        "id": "hYftYKGNcU6W"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 3: DEFINE MODELS TO TEST\n",
        "\n",
        "\n",
        "# We create another dictionary called \"models\".\n",
        "# KEY   = model name (string)\n",
        "# VALUE = the actual ML model wrapped inside a Pipeline.\n",
        "\n",
        "models = {\n",
        "\n",
        "    #  LOGISTIC REGRESSION PIPELINE  (For Classification)\n",
        "\n",
        "    \"Logistic Regression\" : Pipeline([\n",
        "        ('scaler', StandardScaler()),          # Step 1: Standardize features\n",
        "        ('clf', LogisticRegression(max_iter=500))\n",
        "    ]),\n",
        "\n",
        "\n",
        "\n",
        "    #  DECISION TREE PIPELINE (Classifier + Regressor handle below)\n",
        "\n",
        "    \"Decision Tree (Classifier)\" : Pipeline([\n",
        "        ('scaler', StandardScaler()),          # Scaling included for consistency\n",
        "        ('clf', DecisionTreeClassifier())      # Step 2: Tree classifier\n",
        "    ]),\n",
        "\n",
        "    \"Decision Tree (Regressor)\" : Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('reg', DecisionTreeRegressor())       # Step 2: Tree regressor\n",
        "    ]),\n",
        "\n",
        "\n",
        "\n",
        "    # RANDOM FOREST PIPELINE (Classifier + Regressor)\n",
        "\n",
        "    \"Random Forest (Classifier)\" : Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', RandomForestClassifier())\n",
        "    ]),\n",
        "\n",
        "    \"Random Forest (Regressor)\" : Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('reg', RandomForestRegressor())\n",
        "    ]),\n",
        "\n",
        "\n",
        "\n",
        "    #  LINEAR REGRESSION PIPELINE (For Regression datasets)\n",
        "\n",
        "    \"Linear Regression\" : Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('reg', LinearRegression())\n",
        "    ])\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w02RDTJycfq5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  STEP 4: TEST ALL MODELS ON ALL DATASETS\n",
        "\n",
        "\n",
        "for dataset_name, dataset in datasets.items():\n",
        "\n",
        "    print(\"\\n===================================================\")\n",
        "    print(\" DATASET:\", dataset_name)\n",
        "    print(\"===================================================\\n\")\n",
        "\n",
        "\n",
        "    # EXTRACT FEATURES (X) AND LABELS (y)\n",
        "\n",
        "    X = dataset.data\n",
        "    y = dataset.target\n",
        "\n",
        "    # DETERMINE TASK TYPE (manually set)\n",
        "\n",
        "    if dataset_name == \"Wine Dataset\":\n",
        "        current_dataset_task_type = \"classification\"\n",
        "    elif dataset_name in [\"Diabetes Dataset\", \"California Housing\"]:\n",
        "        current_dataset_task_type = \"regression\"\n",
        "    else:\n",
        "        print(\"Unknown dataset type. Skipping...\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    # TRAIN‚ÄìTEST SPLIT\n",
        "\n",
        "    if current_dataset_task_type == \"classification\":\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "\n",
        "    # VARIABLES TO TRACK BEST MODEL\n",
        "\n",
        "    best_model_name = None\n",
        "    best_score = -np.inf\n",
        "\n",
        "    # LOOP THROUGH EACH MODEL\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "\n",
        "        # detect model type\n",
        "        if 'clf' in model.named_steps:\n",
        "            model_task_type = \"classification\"\n",
        "        elif 'reg' in model.named_steps:\n",
        "            model_task_type = \"regression\"\n",
        "        else:\n",
        "            print(f\"Cannot determine model type for {model_name}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # skip mismatched models\n",
        "        if current_dataset_task_type != model_task_type:\n",
        "            print(f\"   ‚ö†Ô∏è Skipping {model_name} for {dataset_name} \"\n",
        "                  f\"(task mismatch: dataset expects {current_dataset_task_type}, model is {model_task_type})\")\n",
        "            continue\n",
        "\n",
        "        # train model\n",
        "        print(f\"üîπ Training Model ({model_task_type}): {model_name}\")\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # score model\n",
        "        score = model.score(X_test, y_test)\n",
        "        print(f\"   ‚û§ Score = {score:.3f}\")\n",
        "\n",
        "        # update best model\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_model_name = model_name\n",
        "\n",
        "\n",
        "    # PRINT BEST MODEL\n",
        "\n",
        "    print(\"\\n‚≠ê‚≠ê BEST MODEL FOR\", dataset_name, \"‚≠ê‚≠ê\")\n",
        "    print(f\"‚û°Ô∏è {best_model_name} with score {best_score:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdW0htVYgm3j",
        "outputId": "29b04534-d755-40c6-82b8-23ea79ba6a95"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================================\n",
            " DATASET: Wine Dataset\n",
            "===================================================\n",
            "\n",
            "üîπ Training Model (classification): Logistic Regression\n",
            "   ‚û§ Score = 0.972\n",
            "üîπ Training Model (classification): Decision Tree (Classifier)\n",
            "   ‚û§ Score = 0.944\n",
            "   ‚ö†Ô∏è Skipping Decision Tree (Regressor) for Wine Dataset (task mismatch: dataset expects classification, model is regression)\n",
            "üîπ Training Model (classification): Random Forest (Classifier)\n",
            "   ‚û§ Score = 1.000\n",
            "   ‚ö†Ô∏è Skipping Random Forest (Regressor) for Wine Dataset (task mismatch: dataset expects classification, model is regression)\n",
            "   ‚ö†Ô∏è Skipping Linear Regression for Wine Dataset (task mismatch: dataset expects classification, model is regression)\n",
            "\n",
            "‚≠ê‚≠ê BEST MODEL FOR Wine Dataset ‚≠ê‚≠ê\n",
            "‚û°Ô∏è Random Forest (Classifier) with score 1.000\n",
            "\n",
            "===================================================\n",
            " DATASET: Diabetes Dataset\n",
            "===================================================\n",
            "\n",
            "   ‚ö†Ô∏è Skipping Logistic Regression for Diabetes Dataset (task mismatch: dataset expects regression, model is classification)\n",
            "   ‚ö†Ô∏è Skipping Decision Tree (Classifier) for Diabetes Dataset (task mismatch: dataset expects regression, model is classification)\n",
            "üîπ Training Model (regression): Decision Tree (Regressor)\n",
            "   ‚û§ Score = 0.103\n",
            "   ‚ö†Ô∏è Skipping Random Forest (Classifier) for Diabetes Dataset (task mismatch: dataset expects regression, model is classification)\n",
            "üîπ Training Model (regression): Random Forest (Regressor)\n",
            "   ‚û§ Score = 0.453\n",
            "üîπ Training Model (regression): Linear Regression\n",
            "   ‚û§ Score = 0.453\n",
            "\n",
            "‚≠ê‚≠ê BEST MODEL FOR Diabetes Dataset ‚≠ê‚≠ê\n",
            "‚û°Ô∏è Random Forest (Regressor) with score 0.453\n",
            "\n",
            "===================================================\n",
            " DATASET: California Housing\n",
            "===================================================\n",
            "\n",
            "   ‚ö†Ô∏è Skipping Logistic Regression for California Housing (task mismatch: dataset expects regression, model is classification)\n",
            "   ‚ö†Ô∏è Skipping Decision Tree (Classifier) for California Housing (task mismatch: dataset expects regression, model is classification)\n",
            "üîπ Training Model (regression): Decision Tree (Regressor)\n",
            "   ‚û§ Score = 0.622\n",
            "   ‚ö†Ô∏è Skipping Random Forest (Classifier) for California Housing (task mismatch: dataset expects regression, model is classification)\n",
            "üîπ Training Model (regression): Random Forest (Regressor)\n",
            "   ‚û§ Score = 0.808\n",
            "üîπ Training Model (regression): Linear Regression\n",
            "   ‚û§ Score = 0.576\n",
            "\n",
            "‚≠ê‚≠ê BEST MODEL FOR California Housing ‚≠ê‚≠ê\n",
            "‚û°Ô∏è Random Forest (Regressor) with score 0.808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AwEZUmtQjXaS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}